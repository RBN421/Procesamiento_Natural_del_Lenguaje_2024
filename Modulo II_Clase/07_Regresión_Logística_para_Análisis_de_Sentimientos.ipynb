{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwY1E6Ac5uew"
      },
      "source": [
        "<img style=\"float: left;;\" src='https://github.com/gdesirena/Procesamiento_Natural_del_Lenguaje_2024/blob/main/Modulo%20II/Figures/alinco.png?raw=1' /></a>\n",
        "\n",
        "# Modulo I: Regresi√≥n Log√≠stica para An√°lisis de Sentimientos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5Aq4ke75ue0"
      },
      "source": [
        "## Importar librer√≠as y funciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXh93k_U5ue1"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from os import getcwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "kTcaMZvj5ue1"
      },
      "outputs": [],
      "source": [
        "# agregue la carpeta, tmp2, desde nuestro espacio de trabajo local que contiene archivos de corpus descargados previamente a la ruta de datos de nltk\n",
        "# esto permite importar estos archivos sin descargarlos nuevamente cuando actualizamos nuestro espacio de trabajo\n",
        "filePath = f\"{getcwd()}/../tmp2\"\n",
        "nltk.data.path.append(filePath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "rhXg3NiD5ue2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import twitter_samples\n",
        "\n",
        "from utils import process_tweet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXHe8aoA5ue2"
      },
      "source": [
        "### Prepara los datos\n",
        "* `twitter_samples` contiene subconjuntos de 5,000 tweets positivos, 5,000 tweets negativos y el conjunto completo de 10,000 tweets.\n",
        "     * Si utiliza los tres conjuntos de datos, introducir√≠amos duplicados de los tweets positivos y negativos.\n",
        "     * Seleccionar√° solo los cinco mil tweets positivos y los cinco mil tweets negativos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "n2j6L1cB5ue3"
      },
      "outputs": [],
      "source": [
        "# select the set of positive and negative tweets\n",
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(%colors)"
      ],
      "metadata": {
        "id": "-4gXg0UiCDVS",
        "outputId": "5e4f6168-6a17-4184-bed0-d00ee096c69a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qCl8pQW5ue3"
      },
      "source": [
        "* Train test split: 20% para test, y 80% para train.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "B_gjUrDV5ue3"
      },
      "outputs": [],
      "source": [
        "# split the data into two pieces, one for training and one for testing (validation set)\n",
        "\n",
        "#Test y train para tweets positivos\n",
        "test_pos = all_positive_tweets[4000:]\n",
        "train_pos = all_positive_tweets[:4000]\n",
        "#Test y train para tweets negativos\n",
        "\n",
        "test_neg = all_negative_tweets[4000:]\n",
        "train_neg = all_negative_tweets[:4000]\n",
        "\n",
        "# Datos de entrenamiento\n",
        "train_x = train_pos + train_neg\n",
        "test_x = test_pos + test_neg\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_GNrrBM5ue4"
      },
      "source": [
        "* Creear una matriz de etiquetas positivas y negativas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "tvLLN9525ue4"
      },
      "outputs": [],
      "source": [
        "# combinar tweets positivos y negativos\n",
        "train_y = np.append(np.ones((len(train_pos),1)), np.zeros((len(train_neg), 1)), axis=0)\n",
        "test_y = np.append(np.ones((len(test_pos),1)), np.zeros((len(test_neg),1)), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "DGElzEbJ5ue4",
        "outputId": "21276e9a-1a62-463d-ef30-e3011f30f6c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 8000)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "# imprimir test y train\n",
        "len(test_y), len(train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "iDawaxjK5ue4",
        "outputId": "6f235c2a-1985-4976-e54d-8c1c603a2600",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the Utilities Constructor\n"
          ]
        }
      ],
      "source": [
        "# crear el diccionario de frecuencias\n",
        "from utilss import Utilities as prep\n",
        "a = prep()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "w_uOfs5EEDUt",
        "outputId": "3a6d39fe-8ae3-4bb1-b014-9bf732c53b6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freqs = a.build_freqs(train_x, train_y)"
      ],
      "metadata": {
        "id": "ZvBPNd57D7xU"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freqs"
      ],
      "metadata": {
        "id": "sSl5QNG3EJbe",
        "outputId": "aae3ab3f-6d19-4cf4-a78d-36760521da2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('followfriday', 1.0): 23,\n",
              " ('top', 1.0): 30,\n",
              " ('engag', 1.0): 7,\n",
              " ('member', 1.0): 14,\n",
              " ('commun', 1.0): 27,\n",
              " ('week', 1.0): 72,\n",
              " (':)', 1.0): 2847,\n",
              " ('hey', 1.0): 60,\n",
              " ('jame', 1.0): 7,\n",
              " ('odd', 1.0): 2,\n",
              " (':/', 1.0): 5,\n",
              " ('pleas', 1.0): 80,\n",
              " ('call', 1.0): 27,\n",
              " ('contact', 1.0): 4,\n",
              " ('centr', 1.0): 1,\n",
              " ('02392441234', 1.0): 1,\n",
              " ('abl', 1.0): 6,\n",
              " ('assist', 1.0): 1,\n",
              " ('mani', 1.0): 28,\n",
              " ('thank', 1.0): 504,\n",
              " ('listen', 1.0): 14,\n",
              " ('last', 1.0): 39,\n",
              " ('night', 1.0): 55,\n",
              " ('bleed', 1.0): 2,\n",
              " ('amaz', 1.0): 41,\n",
              " ('track', 1.0): 5,\n",
              " ('scotland', 1.0): 2,\n",
              " ('congrat', 1.0): 15,\n",
              " ('yeaaah', 1.0): 1,\n",
              " ('yipppi', 1.0): 1,\n",
              " ('accnt', 1.0): 2,\n",
              " ('verifi', 1.0): 2,\n",
              " ('rqst', 1.0): 1,\n",
              " ('succeed', 1.0): 1,\n",
              " ('got', 1.0): 57,\n",
              " ('blue', 1.0): 8,\n",
              " ('tick', 1.0): 1,\n",
              " ('mark', 1.0): 1,\n",
              " ('fb', 1.0): 4,\n",
              " ('profil', 1.0): 2,\n",
              " ('15', 1.0): 4,\n",
              " ('day', 1.0): 187,\n",
              " ('one', 1.0): 90,\n",
              " ('irresist', 1.0): 2,\n",
              " ('flipkartfashionfriday', 1.0): 16,\n",
              " ('like', 1.0): 187,\n",
              " ('keep', 1.0): 55,\n",
              " ('love', 1.0): 336,\n",
              " ('custom', 1.0): 4,\n",
              " ('wait', 1.0): 55,\n",
              " ('long', 1.0): 27,\n",
              " ('hope', 1.0): 113,\n",
              " ('enjoy', 1.0): 57,\n",
              " ('happi', 1.0): 161,\n",
              " ('friday', 1.0): 91,\n",
              " ('lwwf', 1.0): 1,\n",
              " ('second', 1.0): 8,\n",
              " ('thought', 1.0): 21,\n",
              " ('‚Äô', 1.0): 17,\n",
              " ('enough', 1.0): 16,\n",
              " ('time', 1.0): 100,\n",
              " ('dd', 1.0): 1,\n",
              " ('new', 1.0): 111,\n",
              " ('short', 1.0): 6,\n",
              " ('enter', 1.0): 9,\n",
              " ('system', 1.0): 2,\n",
              " ('sheep', 1.0): 1,\n",
              " ('must', 1.0): 14,\n",
              " ('buy', 1.0): 9,\n",
              " ('jgh', 1.0): 4,\n",
              " ('go', 1.0): 120,\n",
              " ('bayan', 1.0): 1,\n",
              " (':d', 1.0): 498,\n",
              " ('bye', 1.0): 5,\n",
              " ('act', 1.0): 6,\n",
              " ('mischiev', 1.0): 1,\n",
              " ('etl', 1.0): 1,\n",
              " ('layer', 1.0): 1,\n",
              " ('in-hous', 1.0): 1,\n",
              " ('wareh', 1.0): 1,\n",
              " ('app', 1.0): 12,\n",
              " ('katamari', 1.0): 1,\n",
              " ('well', 1.0): 66,\n",
              " ('‚Ä¶', 1.0): 31,\n",
              " ('name', 1.0): 12,\n",
              " ('impli', 1.0): 1,\n",
              " (':p', 1.0): 104,\n",
              " ('influenc', 1.0): 16,\n",
              " ('big', 1.0): 27,\n",
              " ('...', 1.0): 227,\n",
              " ('juici', 1.0): 3,\n",
              " ('selfi', 1.0): 11,\n",
              " ('follow', 1.0): 319,\n",
              " ('perfect', 1.0): 17,\n",
              " ('alreadi', 1.0): 19,\n",
              " ('know', 1.0): 120,\n",
              " (\"what'\", 1.0): 14,\n",
              " ('great', 1.0): 134,\n",
              " ('opportun', 1.0): 17,\n",
              " ('junior', 1.0): 2,\n",
              " ('triathlet', 1.0): 1,\n",
              " ('age', 1.0): 2,\n",
              " ('12', 1.0): 5,\n",
              " ('13', 1.0): 5,\n",
              " ('gatorad', 1.0): 1,\n",
              " ('seri', 1.0): 4,\n",
              " ('get', 1.0): 164,\n",
              " ('entri', 1.0): 3,\n",
              " ('lay', 1.0): 3,\n",
              " ('greet', 1.0): 4,\n",
              " ('card', 1.0): 6,\n",
              " ('rang', 1.0): 2,\n",
              " ('print', 1.0): 3,\n",
              " ('today', 1.0): 86,\n",
              " ('job', 1.0): 34,\n",
              " (':-)', 1.0): 543,\n",
              " (\"friend'\", 1.0): 3,\n",
              " ('lunch', 1.0): 3,\n",
              " ('yummm', 1.0): 1,\n",
              " ('nostalgia', 1.0): 1,\n",
              " ('tb', 1.0): 1,\n",
              " ('ku', 1.0): 1,\n",
              " ('id', 1.0): 8,\n",
              " ('conflict', 1.0): 1,\n",
              " ('help', 1.0): 37,\n",
              " (\"here'\", 1.0): 20,\n",
              " ('screenshot', 1.0): 2,\n",
              " ('work', 1.0): 88,\n",
              " ('hi', 1.0): 154,\n",
              " ('liv', 1.0): 2,\n",
              " ('hello', 1.0): 49,\n",
              " ('need', 1.0): 62,\n",
              " ('someth', 1.0): 25,\n",
              " ('u', 1.0): 136,\n",
              " ('fm', 1.0): 2,\n",
              " ('twitter', 1.0): 25,\n",
              " ('‚Äî', 1.0): 22,\n",
              " ('sure', 1.0): 37,\n",
              " ('thing', 1.0): 48,\n",
              " ('dm', 1.0): 34,\n",
              " ('x', 1.0): 50,\n",
              " (\"i'v\", 1.0): 25,\n",
              " ('heard', 1.0): 9,\n",
              " ('four', 1.0): 5,\n",
              " ('season', 1.0): 5,\n",
              " ('pretti', 1.0): 17,\n",
              " ('dope', 1.0): 2,\n",
              " ('penthous', 1.0): 1,\n",
              " ('obv', 1.0): 1,\n",
              " ('gobigorgohom', 1.0): 1,\n",
              " ('fun', 1.0): 45,\n",
              " (\"y'all\", 1.0): 3,\n",
              " ('yeah', 1.0): 30,\n",
              " ('suppos', 1.0): 6,\n",
              " ('lol', 1.0): 48,\n",
              " ('chat', 1.0): 9,\n",
              " ('bit', 1.0): 16,\n",
              " ('youth', 1.0): 14,\n",
              " ('üíÖüèΩ', 1.0): 1,\n",
              " ('üíã', 1.0): 2,\n",
              " ('seen', 1.0): 6,\n",
              " ('year', 1.0): 33,\n",
              " ('rest', 1.0): 9,\n",
              " ('goe', 1.0): 4,\n",
              " ('quickli', 1.0): 3,\n",
              " ('bed', 1.0): 8,\n",
              " ('music', 1.0): 15,\n",
              " ('fix', 1.0): 6,\n",
              " ('dream', 1.0): 17,\n",
              " ('spiritu', 1.0): 1,\n",
              " ('ritual', 1.0): 1,\n",
              " ('festiv', 1.0): 7,\n",
              " ('n√©pal', 1.0): 1,\n",
              " ('begin', 1.0): 4,\n",
              " ('line-up', 1.0): 4,\n",
              " ('left', 1.0): 10,\n",
              " ('see', 1.0): 156,\n",
              " ('sarah', 1.0): 4,\n",
              " ('send', 1.0): 17,\n",
              " ('us', 1.0): 91,\n",
              " ('email', 1.0): 22,\n",
              " ('bitsy@bitdefender.com', 1.0): 1,\n",
              " (\"we'll\", 1.0): 12,\n",
              " ('asap', 1.0): 5,\n",
              " ('kik', 1.0): 16,\n",
              " ('hatessuc', 1.0): 1,\n",
              " ('32429', 1.0): 1,\n",
              " ('kikm', 1.0): 1,\n",
              " ('lgbt', 1.0): 2,\n",
              " ('tinder', 1.0): 1,\n",
              " ('nsfw', 1.0): 1,\n",
              " ('akua', 1.0): 1,\n",
              " ('cumshot', 1.0): 1,\n",
              " ('come', 1.0): 63,\n",
              " ('hous', 1.0): 5,\n",
              " ('nsn_supplement', 1.0): 1,\n",
              " ('effect', 1.0): 2,\n",
              " ('press', 1.0): 1,\n",
              " ('releas', 1.0): 11,\n",
              " ('distribut', 1.0): 1,\n",
              " ('result', 1.0): 2,\n",
              " ('link', 1.0): 13,\n",
              " ('remov', 1.0): 3,\n",
              " ('pressreleas', 1.0): 1,\n",
              " ('newsdistribut', 1.0): 1,\n",
              " ('bam', 1.0): 44,\n",
              " ('bestfriend', 1.0): 50,\n",
              " ('lot', 1.0): 80,\n",
              " ('warsaw', 1.0): 44,\n",
              " ('<3', 1.0): 118,\n",
              " ('x46', 1.0): 1,\n",
              " ('everyon', 1.0): 45,\n",
              " ('watch', 1.0): 32,\n",
              " ('documentari', 1.0): 1,\n",
              " ('earthl', 1.0): 1,\n",
              " ('youtub', 1.0): 8,\n",
              " ('support', 1.0): 25,\n",
              " ('buuut', 1.0): 1,\n",
              " ('oh', 1.0): 44,\n",
              " ('look', 1.0): 109,\n",
              " ('forward', 1.0): 20,\n",
              " ('visit', 1.0): 25,\n",
              " ('next', 1.0): 37,\n",
              " ('letsgetmessi', 1.0): 1,\n",
              " ('jo', 1.0): 1,\n",
              " ('make', 1.0): 69,\n",
              " ('feel', 1.0): 33,\n",
              " ('better', 1.0): 40,\n",
              " ('never', 1.0): 31,\n",
              " ('anyon', 1.0): 7,\n",
              " ('kpop', 1.0): 1,\n",
              " ('flesh', 1.0): 1,\n",
              " ('good', 1.0): 191,\n",
              " ('girl', 1.0): 34,\n",
              " ('best', 1.0): 49,\n",
              " ('wish', 1.0): 29,\n",
              " ('reason', 1.0): 10,\n",
              " ('epic', 1.0): 1,\n",
              " ('soundtrack', 1.0): 1,\n",
              " ('shout', 1.0): 11,\n",
              " ('ad', 1.0): 10,\n",
              " ('video', 1.0): 29,\n",
              " ('playlist', 1.0): 5,\n",
              " ('would', 1.0): 70,\n",
              " ('dear', 1.0): 15,\n",
              " ('jordan', 1.0): 1,\n",
              " ('okay', 1.0): 31,\n",
              " ('fake', 1.0): 1,\n",
              " ('gameplay', 1.0): 1,\n",
              " (';)', 1.0): 22,\n",
              " ('haha', 1.0): 44,\n",
              " ('im', 1.0): 38,\n",
              " ('kid', 1.0): 13,\n",
              " ('stuff', 1.0): 11,\n",
              " ('exactli', 1.0): 5,\n",
              " ('product', 1.0): 11,\n",
              " ('line', 1.0): 6,\n",
              " ('etsi', 1.0): 1,\n",
              " ('shop', 1.0): 12,\n",
              " ('check', 1.0): 38,\n",
              " ('vacat', 1.0): 5,\n",
              " ('recharg', 1.0): 1,\n",
              " ('normal', 1.0): 5,\n",
              " ('charger', 1.0): 2,\n",
              " ('asleep', 1.0): 7,\n",
              " ('talk', 1.0): 37,\n",
              " ('sooo', 1.0): 6,\n",
              " ('someon', 1.0): 29,\n",
              " ('text', 1.0): 12,\n",
              " ('ye', 1.0): 60,\n",
              " ('bet', 1.0): 6,\n",
              " (\"he'll\", 1.0): 2,\n",
              " ('fit', 1.0): 2,\n",
              " ('hear', 1.0): 24,\n",
              " ('speech', 1.0): 1,\n",
              " ('piti', 1.0): 2,\n",
              " ('green', 1.0): 2,\n",
              " ('garden', 1.0): 5,\n",
              " ('midnight', 1.0): 1,\n",
              " ('sun', 1.0): 6,\n",
              " ('beauti', 1.0): 45,\n",
              " ('canal', 1.0): 1,\n",
              " ('dasvidaniya', 1.0): 1,\n",
              " ('till', 1.0): 16,\n",
              " ('scout', 1.0): 1,\n",
              " ('sg', 1.0): 1,\n",
              " ('futur', 1.0): 9,\n",
              " ('wlan', 1.0): 1,\n",
              " ('pro', 1.0): 4,\n",
              " ('confer', 1.0): 1,\n",
              " ('asia', 1.0): 1,\n",
              " ('chang', 1.0): 20,\n",
              " ('lollipop', 1.0): 1,\n",
              " ('üç≠', 1.0): 1,\n",
              " ('nez', 1.0): 1,\n",
              " ('agnezmo', 1.0): 1,\n",
              " ('oley', 1.0): 1,\n",
              " ('mama', 1.0): 1,\n",
              " ('stand', 1.0): 6,\n",
              " ('stronger', 1.0): 1,\n",
              " ('god', 1.0): 14,\n",
              " ('misti', 1.0): 1,\n",
              " ('babi', 1.0): 17,\n",
              " ('cute', 1.0): 21,\n",
              " ('woohoo', 1.0): 3,\n",
              " (\"can't\", 1.0): 31,\n",
              " ('sign', 1.0): 9,\n",
              " ('yet', 1.0): 12,\n",
              " ('still', 1.0): 37,\n",
              " ('think', 1.0): 48,\n",
              " ('mka', 1.0): 5,\n",
              " ('liam', 1.0): 5,\n",
              " ('access', 1.0): 3,\n",
              " ('welcom', 1.0): 54,\n",
              " ('stat', 1.0): 51,\n",
              " ('arriv', 1.0): 57,\n",
              " ('1', 1.0): 60,\n",
              " ('unfollow', 1.0): 53,\n",
              " ('via', 1.0): 60,\n",
              " ('surpris', 1.0): 10,\n",
              " ('figur', 1.0): 5,\n",
              " ('happybirthdayemilybett', 1.0): 1,\n",
              " ('sweet', 1.0): 16,\n",
              " ('talent', 1.0): 4,\n",
              " ('2', 1.0): 41,\n",
              " ('plan', 1.0): 21,\n",
              " ('drain', 1.0): 1,\n",
              " ('gotta', 1.0): 4,\n",
              " ('timezon', 1.0): 1,\n",
              " ('parent', 1.0): 4,\n",
              " ('proud', 1.0): 11,\n",
              " ('least', 1.0): 14,\n",
              " ('mayb', 1.0): 17,\n",
              " ('sometim', 1.0): 11,\n",
              " ('grade', 1.0): 4,\n",
              " ('al', 1.0): 3,\n",
              " ('grand', 1.0): 4,\n",
              " ('manila_bro', 1.0): 1,\n",
              " ('chosen', 1.0): 1,\n",
              " ('let', 1.0): 57,\n",
              " ('around', 1.0): 14,\n",
              " ('..', 1.0): 100,\n",
              " ('side', 1.0): 13,\n",
              " ('world', 1.0): 23,\n",
              " ('eh', 1.0): 2,\n",
              " ('take', 1.0): 30,\n",
              " ('care', 1.0): 12,\n",
              " ('final', 1.0): 24,\n",
              " ('fuck', 1.0): 20,\n",
              " ('weekend', 1.0): 61,\n",
              " ('real', 1.0): 18,\n",
              " ('x45', 1.0): 1,\n",
              " ('join', 1.0): 21,\n",
              " ('hushedcallwithfraydo', 1.0): 1,\n",
              " ('gift', 1.0): 7,\n",
              " ('yeahhh', 1.0): 1,\n",
              " ('hushedpinwithsammi', 1.0): 2,\n",
              " ('event', 1.0): 7,\n",
              " ('might', 1.0): 21,\n",
              " ('luv', 1.0): 4,\n",
              " ('realli', 1.0): 66,\n",
              " ('appreci', 1.0): 28,\n",
              " ('share', 1.0): 41,\n",
              " ('wow', 1.0): 14,\n",
              " ('tom', 1.0): 5,\n",
              " ('gym', 1.0): 3,\n",
              " ('monday', 1.0): 7,\n",
              " ('invit', 1.0): 15,\n",
              " ('scope', 1.0): 5,\n",
              " ('friend', 1.0): 40,\n",
              " ('nude', 1.0): 1,\n",
              " ('sleep', 1.0): 35,\n",
              " ('birthday', 1.0): 53,\n",
              " ('want', 1.0): 69,\n",
              " ('t-shirt', 1.0): 2,\n",
              " ('cool', 1.0): 29,\n",
              " ('haw', 1.0): 1,\n",
              " ('phela', 1.0): 1,\n",
              " ('mom', 1.0): 7,\n",
              " ('obvious', 1.0): 1,\n",
              " ('princ', 1.0): 1,\n",
              " ('charm', 1.0): 1,\n",
              " ('stage', 1.0): 2,\n",
              " ('luck', 1.0): 26,\n",
              " ('tyler', 1.0): 1,\n",
              " ('hipster', 1.0): 1,\n",
              " ('glass', 1.0): 3,\n",
              " ('marti', 1.0): 2,\n",
              " ('glad', 1.0): 41,\n",
              " ('done', 1.0): 40,\n",
              " ('afternoon', 1.0): 7,\n",
              " ('read', 1.0): 27,\n",
              " ('kahfi', 1.0): 1,\n",
              " ('finish', 1.0): 15,\n",
              " ('ohmyg', 1.0): 1,\n",
              " ('yaya', 1.0): 3,\n",
              " ('dub', 1.0): 1,\n",
              " ('stalk', 1.0): 2,\n",
              " ('ig', 1.0): 3,\n",
              " ('gondooo', 1.0): 1,\n",
              " ('moo', 1.0): 2,\n",
              " ('tologooo', 1.0): 1,\n",
              " ('becom', 1.0): 8,\n",
              " ('detail', 1.0): 8,\n",
              " ('zzz', 1.0): 1,\n",
              " ('xx', 1.0): 33,\n",
              " ('physiotherapi', 1.0): 1,\n",
              " ('hashtag', 1.0): 3,\n",
              " ('üí™', 1.0): 1,\n",
              " ('monica', 1.0): 1,\n",
              " ('miss', 1.0): 17,\n",
              " ('sound', 1.0): 20,\n",
              " ('morn', 1.0): 68,\n",
              " (\"that'\", 1.0): 49,\n",
              " ('x43', 1.0): 1,\n",
              " ('definit', 1.0): 20,\n",
              " ('tri', 1.0): 34,\n",
              " ('tonight', 1.0): 15,\n",
              " ('took', 1.0): 7,\n",
              " ('advic', 1.0): 6,\n",
              " ('treviso', 1.0): 1,\n",
              " ('concert', 1.0): 23,\n",
              " ('citi', 1.0): 26,\n",
              " ('countri', 1.0): 22,\n",
              " (\"i'll\", 1.0): 73,\n",
              " ('start', 1.0): 56,\n",
              " ('fine', 1.0): 7,\n",
              " ('gorgeou', 1.0): 9,\n",
              " ('xo', 1.0): 2,\n",
              " ('oven', 1.0): 2,\n",
              " ('roast', 1.0): 1,\n",
              " ('garlic', 1.0): 1,\n",
              " ('oliv', 1.0): 1,\n",
              " ('oil', 1.0): 4,\n",
              " ('dri', 1.0): 4,\n",
              " ('tomato', 1.0): 1,\n",
              " ('basil', 1.0): 1,\n",
              " ('centuri', 1.0): 1,\n",
              " ('tuna', 1.0): 1,\n",
              " ('right', 1.0): 38,\n",
              " ('back', 1.0): 74,\n",
              " ('atchya', 1.0): 1,\n",
              " ('even', 1.0): 26,\n",
              " ('almost', 1.0): 8,\n",
              " ('chanc', 1.0): 3,\n",
              " ('cheer', 1.0): 17,\n",
              " ('po', 1.0): 3,\n",
              " ('ice', 1.0): 6,\n",
              " ('cream', 1.0): 6,\n",
              " ('agre', 1.0): 13,\n",
              " ('100', 1.0): 6,\n",
              " ('heheheh', 1.0): 2,\n",
              " ('that', 1.0): 10,\n",
              " ('point', 1.0): 11,\n",
              " ('stay', 1.0): 20,\n",
              " ('home', 1.0): 20,\n",
              " ('soon', 1.0): 38,\n",
              " ('promis', 1.0): 4,\n",
              " ('web', 1.0): 4,\n",
              " ('whatsapp', 1.0): 3,\n",
              " ('volta', 1.0): 1,\n",
              " ('funcionar', 1.0): 1,\n",
              " ('com', 1.0): 2,\n",
              " ('iphon', 1.0): 7,\n",
              " ('jailbroken', 1.0): 1,\n",
              " ('later', 1.0): 11,\n",
              " ('34', 1.0): 3,\n",
              " ('min', 1.0): 7,\n",
              " ('leia', 1.0): 1,\n",
              " ('appear', 1.0): 3,\n",
              " ('hologram', 1.0): 1,\n",
              " ('r2d2', 1.0): 1,\n",
              " ('w', 1.0): 16,\n",
              " ('messag', 1.0): 9,\n",
              " ('obi', 1.0): 1,\n",
              " ('wan', 1.0): 1,\n",
              " ('sit', 1.0): 7,\n",
              " ('luke', 1.0): 4,\n",
              " ('inter', 1.0): 1,\n",
              " ('3', 1.0): 25,\n",
              " ('ucl', 1.0): 1,\n",
              " ('arsen', 1.0): 2,\n",
              " ('small', 1.0): 1,\n",
              " ('team', 1.0): 24,\n",
              " ('pass', 1.0): 10,\n",
              " ('üöÇ', 1.0): 1,\n",
              " ('dewsburi', 1.0): 2,\n",
              " ('railway', 1.0): 1,\n",
              " ('station', 1.0): 4,\n",
              " ('dew', 1.0): 1,\n",
              " ('west', 1.0): 1,\n",
              " ('yorkshir', 1.0): 2,\n",
              " ('430', 1.0): 1,\n",
              " ('smh', 1.0): 2,\n",
              " ('9:25', 1.0): 1,\n",
              " ('live', 1.0): 21,\n",
              " ('strang', 1.0): 4,\n",
              " ('imagin', 1.0): 5,\n",
              " ('megan', 1.0): 1,\n",
              " ('masaantoday', 1.0): 4,\n",
              " ('a4', 1.0): 3,\n",
              " ('shweta', 1.0): 1,\n",
              " ('tripathi', 1.0): 1,\n",
              " ('5', 1.0): 15,\n",
              " ('20', 1.0): 5,\n",
              " ('kurta', 1.0): 3,\n",
              " ('half', 1.0): 6,\n",
              " ('number', 1.0): 11,\n",
              " ('wsalelov', 1.0): 14,\n",
              " ('ah', 1.0): 12,\n",
              " ('larri', 1.0): 3,\n",
              " ('anyway', 1.0): 14,\n",
              " ('kinda', 1.0): 12,\n",
              " ('goood', 1.0): 1,\n",
              " ('life', 1.0): 36,\n",
              " ('enn', 1.0): 1,\n",
              " ('could', 1.0): 25,\n",
              " ('warmup', 1.0): 1,\n",
              " ('15th', 1.0): 2,\n",
              " ('bath', 1.0): 6,\n",
              " ('dum', 1.0): 2,\n",
              " ('andar', 1.0): 1,\n",
              " ('ram', 1.0): 1,\n",
              " ('sampath', 1.0): 1,\n",
              " ('sona', 1.0): 1,\n",
              " ('mohapatra', 1.0): 1,\n",
              " ('samantha', 1.0): 1,\n",
              " ('edward', 1.0): 1,\n",
              " ('mein', 1.0): 1,\n",
              " ('tulan', 1.0): 1,\n",
              " ('razi', 1.0): 2,\n",
              " ('wah', 1.0): 2,\n",
              " ('josh', 1.0): 1,\n",
              " ('alway', 1.0): 48,\n",
              " ('smile', 1.0): 47,\n",
              " ('pictur', 1.0): 7,\n",
              " ('16.20', 1.0): 1,\n",
              " ('giveitup', 1.0): 1,\n",
              " ('given', 1.0): 3,\n",
              " ('ga', 1.0): 3,\n",
              " ('subsidi', 1.0): 1,\n",
              " ('initi', 1.0): 2,\n",
              " ('propos', 1.0): 3,\n",
              " ('delight', 1.0): 4,\n",
              " ('yesterday', 1.0): 4,\n",
              " ('x42', 1.0): 1,\n",
              " ('lmaoo', 1.0): 2,\n",
              " ('song', 1.0): 16,\n",
              " ('ever', 1.0): 19,\n",
              " ('shall', 1.0): 5,\n",
              " ('littl', 1.0): 29,\n",
              " ('throwback', 1.0): 3,\n",
              " ('outli', 1.0): 1,\n",
              " ('island', 1.0): 2,\n",
              " ('cheung', 1.0): 1,\n",
              " ('chau', 1.0): 1,\n",
              " ('mui', 1.0): 1,\n",
              " ('wo', 1.0): 1,\n",
              " ('total', 1.0): 5,\n",
              " ('differ', 1.0): 10,\n",
              " ('kfckitchentour', 1.0): 2,\n",
              " ('kitchen', 1.0): 3,\n",
              " ('clean', 1.0): 1,\n",
              " (\"i'm\", 1.0): 140,\n",
              " ('cusp', 1.0): 1,\n",
              " ('test', 1.0): 7,\n",
              " ('water', 1.0): 7,\n",
              " ('reward', 1.0): 1,\n",
              " ('arummzz', 1.0): 2,\n",
              " (\"let'\", 1.0): 18,\n",
              " ('drive', 1.0): 9,\n",
              " ('travel', 1.0): 19,\n",
              " ('yogyakarta', 1.0): 3,\n",
              " ('jeep', 1.0): 3,\n",
              " ('indonesia', 1.0): 3,\n",
              " ('instamood', 1.0): 3,\n",
              " ('wanna', 1.0): 23,\n",
              " ('skype', 1.0): 3,\n",
              " ('may', 1.0): 16,\n",
              " ('nice', 1.0): 70,\n",
              " ('friendli', 1.0): 1,\n",
              " ('pretend', 1.0): 2,\n",
              " ('film', 1.0): 8,\n",
              " ('congratul', 1.0): 9,\n",
              " ('winner', 1.0): 3,\n",
              " ('cheesydelight', 1.0): 1,\n",
              " ('contest', 1.0): 5,\n",
              " ('address', 1.0): 8,\n",
              " ('guy', 1.0): 48,\n",
              " ('market', 1.0): 5,\n",
              " ('24/7', 1.0): 1,\n",
              " ('14', 1.0): 1,\n",
              " ('hour', 1.0): 24,\n",
              " ('leav', 1.0): 11,\n",
              " ('without', 1.0): 9,\n",
              " ('delay', 1.0): 1,\n",
              " ('actual', 1.0): 13,\n",
              " ('easi', 1.0): 7,\n",
              " ('guess', 1.0): 8,\n",
              " ('train', 1.0): 7,\n",
              " ('wd', 1.0): 1,\n",
              " ('shift', 1.0): 4,\n",
              " ('engin', 1.0): 1,\n",
              " ('etc', 1.0): 2,\n",
              " ('sunburn', 1.0): 1,\n",
              " ('peel', 1.0): 2,\n",
              " ('blog', 1.0): 27,\n",
              " ('huge', 1.0): 9,\n",
              " ('warm', 1.0): 4,\n",
              " ('‚òÜ', 1.0): 3,\n",
              " ('complet', 1.0): 10,\n",
              " ('triangl', 1.0): 2,\n",
              " ('northern', 1.0): 1,\n",
              " ('ireland', 1.0): 2,\n",
              " ('sight', 1.0): 1,\n",
              " ('smthng', 1.0): 2,\n",
              " ('fr', 1.0): 3,\n",
              " ('hug', 1.0): 11,\n",
              " ('xoxo', 1.0): 3,\n",
              " ('uu', 1.0): 1,\n",
              " ('jaann', 1.0): 1,\n",
              " ('topnewfollow', 1.0): 2,\n",
              " ('connect', 1.0): 13,\n",
              " ('wonder', 1.0): 26,\n",
              " ('made', 1.0): 38,\n",
              " ('fluffi', 1.0): 1,\n",
              " ('insid', 1.0): 7,\n",
              " ('pirouett', 1.0): 1,\n",
              " ('moos', 1.0): 1,\n",
              " ('trip', 1.0): 12,\n",
              " ('philli', 1.0): 1,\n",
              " ('decemb', 1.0): 2,\n",
              " (\"i'd\", 1.0): 13,\n",
              " ('dude', 1.0): 6,\n",
              " ('x41', 1.0): 1,\n",
              " ('question', 1.0): 15,\n",
              " ('flaw', 1.0): 1,\n",
              " ('pain', 1.0): 8,\n",
              " ('negat', 1.0): 1,\n",
              " ('strength', 1.0): 2,\n",
              " ('went', 1.0): 10,\n",
              " ('solo', 1.0): 4,\n",
              " ('move', 1.0): 9,\n",
              " ('fav', 1.0): 11,\n",
              " ('nirvana', 1.0): 1,\n",
              " ('smell', 1.0): 2,\n",
              " ('teen', 1.0): 3,\n",
              " ('spirit', 1.0): 1,\n",
              " ('rip', 1.0): 3,\n",
              " ('ami', 1.0): 4,\n",
              " ('winehous', 1.0): 1,\n",
              " ('coupl', 1.0): 5,\n",
              " ('tomhiddleston', 1.0): 1,\n",
              " ('elizabetholsen', 1.0): 1,\n",
              " ('yaytheylookgreat', 1.0): 1,\n",
              " ('goodnight', 1.0): 18,\n",
              " ('vid', 1.0): 8,\n",
              " ('wake', 1.0): 10,\n",
              " ('gonna', 1.0): 16,\n",
              " ('shoot', 1.0): 5,\n",
              " ('itti', 1.0): 2,\n",
              " ('bitti', 1.0): 2,\n",
              " ('teeni', 1.0): 2,\n",
              " ('bikini', 1.0): 3,\n",
              " ('much', 1.0): 73,\n",
              " ('4th', 1.0): 4,\n",
              " ('togeth', 1.0): 6,\n",
              " ('end', 1.0): 13,\n",
              " ('xfile', 1.0): 1,\n",
              " ('content', 1.0): 3,\n",
              " ('rain', 1.0): 18,\n",
              " ('fabul', 1.0): 4,\n",
              " ('fantast', 1.0): 8,\n",
              " ('‚ô°', 1.0): 12,\n",
              " ('jb', 1.0): 1,\n",
              " ('forev', 1.0): 5,\n",
              " ('belieb', 1.0): 3,\n",
              " ('nighti', 1.0): 1,\n",
              " ('bug', 1.0): 2,\n",
              " ('bite', 1.0): 1,\n",
              " ('bracelet', 1.0): 2,\n",
              " ('idea', 1.0): 23,\n",
              " ('foundri', 1.0): 1,\n",
              " ('game', 1.0): 23,\n",
              " ('sens', 1.0): 6,\n",
              " ('pic', 1.0): 21,\n",
              " ('ef', 1.0): 1,\n",
              " ('phone', 1.0): 16,\n",
              " ('woot', 1.0): 2,\n",
              " ('derek', 1.0): 1,\n",
              " ('use', 1.0): 32,\n",
              " ('parkshar', 1.0): 1,\n",
              " ('gloucestershir', 1.0): 1,\n",
              " ('aaaahhh', 1.0): 1,\n",
              " ('man', 1.0): 16,\n",
              " ('traffic', 1.0): 2,\n",
              " ('stress', 1.0): 4,\n",
              " ('reliev', 1.0): 1,\n",
              " (\"how'r\", 1.0): 1,\n",
              " ('arbeloa', 1.0): 1,\n",
              " ('turn', 1.0): 13,\n",
              " ('17', 1.0): 2,\n",
              " ('omg', 1.0): 13,\n",
              " ('say', 1.0): 43,\n",
              " ('europ', 1.0): 1,\n",
              " ('rise', 1.0): 2,\n",
              " ('find', 1.0): 20,\n",
              " ('hard', 1.0): 9,\n",
              " ('believ', 1.0): 7,\n",
              " ('uncount', 1.0): 1,\n",
              " ('coz', 1.0): 2,\n",
              " ('unlimit', 1.0): 1,\n",
              " ('cours', 1.0): 11,\n",
              " ('teamposit', 1.0): 1,\n",
              " ('aldub', 1.0): 2,\n",
              " ('‚òï', 1.0): 3,\n",
              " ('rita', 1.0): 2,\n",
              " ('info', 1.0): 10,\n",
              " (\"we'd\", 1.0): 4,\n",
              " ('way', 1.0): 34,\n",
              " ('boy', 1.0): 13,\n",
              " ('x40', 1.0): 1,\n",
              " ('true', 1.0): 19,\n",
              " ('sethi', 1.0): 2,\n",
              " ('high', 1.0): 6,\n",
              " ('exe', 1.0): 1,\n",
              " ('skeem', 1.0): 1,\n",
              " ('saam', 1.0): 1,\n",
              " ('peopl', 1.0): 42,\n",
              " ('polit', 1.0): 2,\n",
              " ('izzat', 1.0): 1,\n",
              " ('wese', 1.0): 1,\n",
              " ('trust', 1.0): 7,\n",
              " ('khawateen', 1.0): 1,\n",
              " ('k', 1.0): 8,\n",
              " ('sath', 1.0): 2,\n",
              " ('mana', 1.0): 1,\n",
              " ('kar', 1.0): 1,\n",
              " ('deya', 1.0): 1,\n",
              " ('sort', 1.0): 7,\n",
              " ('smart', 1.0): 5,\n",
              " ('hair', 1.0): 7,\n",
              " ('tbh', 1.0): 5,\n",
              " ('jacob', 1.0): 2,\n",
              " ('g', 1.0): 7,\n",
              " ('upgrad', 1.0): 2,\n",
              " ('tee', 1.0): 2,\n",
              " ('famili', 1.0): 14,\n",
              " ('person', 1.0): 14,\n",
              " ('two', 1.0): 15,\n",
              " ('convers', 1.0): 6,\n",
              " ('onlin', 1.0): 4,\n",
              " ('mclaren', 1.0): 1,\n",
              " ('fridayfeel', 1.0): 5,\n",
              " ('tgif', 1.0): 8,\n",
              " ('squar', 1.0): 1,\n",
              " ('enix', 1.0): 1,\n",
              " ('bissmillah', 1.0): 1,\n",
              " ('ya', 1.0): 19,\n",
              " ('allah', 1.0): 3,\n",
              " (\"we'r\", 1.0): 25,\n",
              " ('socent', 1.0): 1,\n",
              " ('startup', 1.0): 2,\n",
              " ('drop', 1.0): 9,\n",
              " ('your', 1.0): 3,\n",
              " ('arnd', 1.0): 1,\n",
              " ('town', 1.0): 3,\n",
              " ('basic', 1.0): 4,\n",
              " ('piss', 1.0): 2,\n",
              " ('cup', 1.0): 4,\n",
              " ('also', 1.0): 28,\n",
              " ('terribl', 1.0): 2,\n",
              " ('complic', 1.0): 1,\n",
              " ('discuss', 1.0): 2,\n",
              " ('snapchat', 1.0): 31,\n",
              " ('lynettelow', 1.0): 1,\n",
              " ('kikmenow', 1.0): 2,\n",
              " ('snapm', 1.0): 1,\n",
              " ('hot', 1.0): 20,\n",
              " ('amazon', 1.0): 1,\n",
              " ('kikmeguy', 1.0): 2,\n",
              " ('defin', 1.0): 2,\n",
              " ('grow', 1.0): 6,\n",
              " ('sport', 1.0): 4,\n",
              " ('rt', 1.0): 9,\n",
              " ('rakyat', 1.0): 1,\n",
              " ('write', 1.0): 11,\n",
              " ('sinc', 1.0): 11,\n",
              " ('mention', 1.0): 18,\n",
              " ('fli', 1.0): 5,\n",
              " ('fish', 1.0): 3,\n",
              " ('promot', 1.0): 3,\n",
              " ('post', 1.0): 16,\n",
              " ('cyber', 1.0): 1,\n",
              " ('ourdaughtersourprid', 1.0): 3,\n",
              " ('mypapamyprid', 1.0): 2,\n",
              " ('papa', 1.0): 1,\n",
              " ('coach', 1.0): 2,\n",
              " ('posit', 1.0): 3,\n",
              " ('kha', 1.0): 1,\n",
              " ('atleast', 1.0): 2,\n",
              " ('x39', 1.0): 1,\n",
              " ('mango', 1.0): 1,\n",
              " (\"lassi'\", 1.0): 1,\n",
              " (\"monty'\", 1.0): 1,\n",
              " ('marvel', 1.0): 2,\n",
              " ('though', 1.0): 16,\n",
              " ('suspect', 1.0): 3,\n",
              " ('meant', 1.0): 2,\n",
              " ('24', 1.0): 3,\n",
              " ('hr', 1.0): 2,\n",
              " ('touch', 1.0): 7,\n",
              " ('kepler', 1.0): 3,\n",
              " ('452b', 1.0): 4,\n",
              " ('chalna', 1.0): 1,\n",
              " ('hai', 1.0): 7,\n",
              " ('thankyou', 1.0): 12,\n",
              " ('hazel', 1.0): 1,\n",
              " ('food', 1.0): 6,\n",
              " ('brooklyn', 1.0): 1,\n",
              " ('pta', 1.0): 2,\n",
              " ('awak', 1.0): 8,\n",
              " ('okayi', 1.0): 2,\n",
              " ('awww', 1.0): 12,\n",
              " ('ha', 1.0): 18,\n",
              " ('doc', 1.0): 1,\n",
              " ('splendid', 1.0): 1,\n",
              " ('spam', 1.0): 1,\n",
              " ('folder', 1.0): 1,\n",
              " ('amount', 1.0): 1,\n",
              " ('nigeria', 1.0): 1,\n",
              " ('claim', 1.0): 1,\n",
              " ('rted', 1.0): 1,\n",
              " ('leg', 1.0): 3,\n",
              " ('hurt', 1.0): 4,\n",
              " ('bad', 1.0): 14,\n",
              " ('mine', 1.0): 11,\n",
              " ('saturday', 1.0): 5,\n",
              " ('thaaank', 1.0): 1,\n",
              " ('puhon', 1.0): 1,\n",
              " ('happinesss', 1.0): 1,\n",
              " ('tnc', 1.0): 1,\n",
              " ('prior', 1.0): 1,\n",
              " ('notif', 1.0): 2,\n",
              " ('fat', 1.0): 1,\n",
              " ('co', 1.0): 1,\n",
              " ('probabl', 1.0): 7,\n",
              " ('ate', 1.0): 4,\n",
              " ('yuna', 1.0): 2,\n",
              " ('tamesid', 1.0): 1,\n",
              " ('¬¥', 1.0): 3,\n",
              " ('googl', 1.0): 5,\n",
              " ('account', 1.0): 17,\n",
              " ('scouser', 1.0): 1,\n",
              " ('everyth', 1.0): 10,\n",
              " ('zoe', 1.0): 1,\n",
              " ('mate', 1.0): 5,\n",
              " ('liter', 1.0): 5,\n",
              " (\"they'r\", 1.0): 10,\n",
              " ('samee', 1.0): 1,\n",
              " ('edgar', 1.0): 1,\n",
              " ('updat', 1.0): 12,\n",
              " ('log', 1.0): 3,\n",
              " ('bring', 1.0): 12,\n",
              " ('abe', 1.0): 1,\n",
              " ('meet', 1.0): 26,\n",
              " ('x38', 1.0): 1,\n",
              " ('sigh', 1.0): 3,\n",
              " ('dreamili', 1.0): 1,\n",
              " ('pout', 1.0): 1,\n",
              " ('eye', 1.0): 12,\n",
              " ('quacketyquack', 1.0): 6,\n",
              " ('funni', 1.0): 15,\n",
              " ('happen', 1.0): 13,\n",
              " ('phil', 1.0): 1,\n",
              " ('em', 1.0): 2,\n",
              " ('del', 1.0): 1,\n",
              " ('rodder', 1.0): 1,\n",
              " ('els', 1.0): 8,\n",
              " ('play', 1.0): 37,\n",
              " ('newest', 1.0): 1,\n",
              " ('gamejam', 1.0): 1,\n",
              " ('irish', 1.0): 2,\n",
              " ('literatur', 1.0): 2,\n",
              " ('inaccess', 1.0): 2,\n",
              " (\"kareena'\", 1.0): 2,\n",
              " ('fan', 1.0): 21,\n",
              " ('brain', 1.0): 10,\n",
              " ('dot', 1.0): 8,\n",
              " ('braindot', 1.0): 8,\n",
              " ('fair', 1.0): 4,\n",
              " ('rush', 1.0): 1,\n",
              " ('either', 1.0): 10,\n",
              " ('brandi', 1.0): 1,\n",
              " ('18', 1.0): 5,\n",
              " ('carniv', 1.0): 1,\n",
              " ('men', 1.0): 8,\n",
              " ('put', 1.0): 11,\n",
              " ('mask', 1.0): 2,\n",
              " ('xavier', 1.0): 1,\n",
              " ('forneret', 1.0): 1,\n",
              " ('jennif', 1.0): 1,\n",
              " ('site', 1.0): 7,\n",
              " ('free', 1.0): 31,\n",
              " ('50.000', 1.0): 3,\n",
              " ('8', 1.0): 10,\n",
              " ('ball', 1.0): 7,\n",
              " ('pool', 1.0): 5,\n",
              " ('coin', 1.0): 5,\n",
              " ('edit', 1.0): 6,\n",
              " ('trish', 1.0): 1,\n",
              " ('‚ô•', 1.0): 13,\n",
              " ('grate', 1.0): 5,\n",
              " ('three', 1.0): 8,\n",
              " ('comment', 1.0): 7,\n",
              " ('wakeup', 1.0): 1,\n",
              " ('besid', 1.0): 2,\n",
              " ('dirti', 1.0): 2,\n",
              " ('sex', 1.0): 4,\n",
              " ('lmaooo', 1.0): 1,\n",
              " ('üò§', 1.0): 2,\n",
              " ('loui', 1.0): 4,\n",
              " (\"he'\", 1.0): 10,\n",
              " ('throw', 1.0): 3,\n",
              " ('caus', 1.0): 11,\n",
              " ('inspir', 1.0): 6,\n",
              " ('ff', 1.0): 40,\n",
              " ('twoof', 1.0): 3,\n",
              " ('gr8', 1.0): 1,\n",
              " ('wkend', 1.0): 3,\n",
              " ('kind', 1.0): 22,\n",
              " ('exhaust', 1.0): 2,\n",
              " ('word', 1.0): 17,\n",
              " ('cheltenham', 1.0): 1,\n",
              " ('area', 1.0): 4,\n",
              " ('kale', 1.0): 1,\n",
              " ('crisp', 1.0): 1,\n",
              " ('ruin', 1.0): 5,\n",
              " ('x37', 1.0): 1,\n",
              " ('open', 1.0): 12,\n",
              " ('worldwid', 1.0): 2,\n",
              " ('outta', 1.0): 1,\n",
              " ('sfvbeta', 1.0): 1,\n",
              " ('vantast', 1.0): 1,\n",
              " ('xcylin', 1.0): 1,\n",
              " ('bundl', 1.0): 1,\n",
              " ('show', 1.0): 20,\n",
              " ('internet', 1.0): 2,\n",
              " ('price', 1.0): 3,\n",
              " ('realisticli', 1.0): 1,\n",
              " ('pay', 1.0): 8,\n",
              " ('net', 1.0): 1,\n",
              " ('educ', 1.0): 1,\n",
              " ('power', 1.0): 6,\n",
              " ('weapon', 1.0): 1,\n",
              " ('nelson', 1.0): 1,\n",
              " ('mandela', 1.0): 1,\n",
              " ('recent', 1.0): 8,\n",
              " ('j', 1.0): 2,\n",
              " ('chenab', 1.0): 1,\n",
              " ('flow', 1.0): 5,\n",
              " ('pakistan', 1.0): 1,\n",
              " ('incredibleindia', 1.0): 1,\n",
              " ('teenchoic', 1.0): 7,\n",
              " ('choiceinternationalartist', 1.0): 7,\n",
              " ('superjunior', 1.0): 7,\n",
              " ('caught', 1.0): 4,\n",
              " ('first', 1.0): 41,\n",
              " ('salmon', 1.0): 1,\n",
              " ('super-blend', 1.0): 1,\n",
              " ('project', 1.0): 6,\n",
              " ('youth@bipolaruk.org.uk', 1.0): 1,\n",
              " ('awesom', 1.0): 35,\n",
              " ('stream', 1.0): 12,\n",
              " ('alma', 1.0): 1,\n",
              " ('mater', 1.0): 1,\n",
              " ('highschoolday', 1.0): 1,\n",
              " ('clientvisit', 1.0): 1,\n",
              " ('faith', 1.0): 3,\n",
              " ('christian', 1.0): 1,\n",
              " ('school', 1.0): 9,\n",
              " ('lizaminnelli', 1.0): 1,\n",
              " ('upcom', 1.0): 2,\n",
              " ('uk', 1.0): 4,\n",
              " ('üòÑ', 1.0): 3,\n",
              " ('singl', 1.0): 4,\n",
              " ('hill', 1.0): 4,\n",
              " ('everi', 1.0): 23,\n",
              " ('beat', 1.0): 7,\n",
              " ('wrong', 1.0): 9,\n",
              " ('readi', 1.0): 22,\n",
              " ('natur', 1.0): 1,\n",
              " ('pefumeri', 1.0): 1,\n",
              " ('workshop', 1.0): 2,\n",
              " ('neal', 1.0): 1,\n",
              " ('yard', 1.0): 1,\n",
              " ('covent', 1.0): 1,\n",
              " ('tomorrow', 1.0): 31,\n",
              " ('fback', 1.0): 26,\n",
              " ('indo', 1.0): 1,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GMTiRlR5ue5"
      },
      "source": [
        "### Procesamiento del tweet\n",
        "\n",
        "La funci√≥n dada `process_tweet ()` tokeniza el tweet en palabras individuales, elimina las palabras vac√≠as y aplica la derivaci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "_4zf0a2z5ue5",
        "outputId": "b9d29c2b-0ea8-47e3-888e-02744f2ce194",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['followfriday', 'top', 'engag', 'member', 'commun', 'week', ':)']"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "process_tweet(train_x[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKXLOd8Q5ue5"
      },
      "source": [
        "##  Extrayendo las caracter√≠sticas\n",
        "\n",
        "* Dada una lista de tweets, extraiga las caracter√≠sticas y gu√°rdelas en una matriz. Extraer√°s dos caracter√≠sticas.\n",
        "     * La primera caracter√≠stica es la cantidad de palabras positivas en un tweet.\n",
        "     * La segunda caracter√≠stica es la cantidad de palabras negativas en un tweet.\n",
        "* Luego entrene su clasificador de regresi√≥n log√≠stica en estas caracter√≠sticas.\n",
        "* Pruebe el clasificador en un conjunto de validaci√≥n.\n",
        "\n",
        "### Implementaci√≥n de la funci√≥n de extract_features.\n",
        "* Esta funci√≥n admite un solo tweet.\n",
        "* Procesaremos el tweet usando la funci√≥n `process_tweet()` importada y la guardaremos en la lista de palabras del tweet.\n",
        "* Recorreremos cada palabra en la lista de palabras procesadas\n",
        "     * Para cada palabra, consultaremos el diccionario `freqs` para el recuento cuando esa palabra tiene una etiqueta positiva '1'. (con clave (palabra, 1.0)\n",
        "     * Hacemos lo mismo con el recuento para cuando la palabra est√© asociada con la etiqueta negativa '0'. (con la clave (palabra, 0.0).)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freqs.get(('followfriday',1.0), 1)\n"
      ],
      "metadata": {
        "id": "2Cn4Q8FYGvrt",
        "outputId": "94c17efa-3a4f-44b7-d122-918edbfdbc35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "Qu_gNJyl5ue5"
      },
      "outputs": [],
      "source": [
        "def extract_features(tweet, freqs):\n",
        "    # procesar el tweet (tokenizar, stems, remover stopwords, regex)\n",
        "    word_l = process_tweet(tweet)\n",
        "\n",
        "    #Crear el vector x (1x3)\n",
        "    x = np.zeros((1,3))\n",
        "    #bias en 1\n",
        "    x[0,0]=1\n",
        "\n",
        "    for word in word_l:\n",
        "      #El conteo para los tokens que vienen de un tweet positivo\n",
        "      x[0,1] += freqs.get((word,1.0), 1)\n",
        "\n",
        "      #El conteo de los tokens que vienen de un tweet negativo\n",
        "      x[0,2] += freqs.get((word,0.0),0)\n",
        "\n",
        "    assert(x.shape==(1,3))\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "ILxo32_z5ue5",
        "outputId": "3c89775c-ebc5-4dab-a2c6-202d92b1af43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.00e+00 3.02e+03 6.10e+01]]\n"
          ]
        }
      ],
      "source": [
        "# checar la funci√≥n\n",
        "tmp1 = extract_features(train_x[0], freqs)\n",
        "print(tmp1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CLg3M7K5ue5"
      },
      "source": [
        "# Implementaci√≥n de la Regresi√≥n Log√≠stica\n",
        "\n",
        "\n",
        "### Funci√≥n sigmoide\n",
        "Aprender√° a utilizar la regresi√≥n log√≠stica para la clasificaci√≥n de texto.\n",
        "* La funci√≥n sigmoidea se define como:\n",
        "\n",
        "$$ h(z) = \\frac{1}{1+\\exp^{-z}} \\tag{1}$$\n",
        "\n",
        "Asigna la entrada 'z' a un valor que var√≠a entre 0 y 1, por lo que puede tratarse como una probabilidad.\n",
        "\n",
        "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='https://github.com/gdesirena/Procesamiento_Natural_del_Lenguaje_2024/blob/main/Modulo%20II/Figures/sigmoid_plot.jpg?raw=1' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:300px;height:200px;\" /> </div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "QOH1JIVc5ue6"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "    h = 1 / (1 + np.exp(-z))\n",
        "    return h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "MAzeiHzN5ue6",
        "outputId": "3a9e7b53-a0cf-4590-e28a-d7101b1a6181",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "# probar la funci√≥n\n",
        "sigmoid(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sigmoid(4.58)"
      ],
      "metadata": {
        "id": "wQRCOt4FHbGg",
        "outputId": "43a30305-3cf0-403a-a1c8-f0bf09d0e946",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9898491991140074"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sigmoid(-4.58)"
      ],
      "metadata": {
        "id": "9rHtG61yHbOB",
        "outputId": "930cb3ad-54d2-4a86-ab04-6d770be525c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.01015080088599272"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6GQFszv5ue6"
      },
      "source": [
        "### Logistic regression: regression y funci√≥n sigmoide\n",
        "\n",
        "La regresi√≥n log√≠stica toma una regresi√≥n lineal regular y aplica un sigmoide a la salida de la regresi√≥n lineal.\n",
        "\n",
        "Regresion:\n",
        "$$z = \\theta_0 x_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... \\theta_N x_N$$\n",
        "Tenga en cuenta que los valores $ \\theta $ son \"pesos\". Si realiz√≥ la especializaci√≥n en aprendizaje profundo, nos referimos a los pesos con el vector `w`. En este curso, usamos una variable diferente $ \\theta $ para referirnos a los pesos.\n",
        "\n",
        "Regresi√≥n log√≠stica\n",
        "$$ h(z) = \\frac{1}{1+\\exp^{-z}}$$\n",
        "$$z = \\theta_0 x_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... \\theta_N x_N$$\n",
        "Nos referiremos a 'z' como los 'logits'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB2Wt_u65ue6"
      },
      "source": [
        "### Funci√≥n de costo y gradiente\n",
        "\n",
        "La funci√≥n de costo utilizada para la regresi√≥n log√≠stica es el promedio de la p√©rdida de registro en todos los ejemplos de entrenamiento:\n",
        "\n",
        "$$J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^m y^{(i)}\\log (h(z(\\theta)^{(i)})) + (1-y^{(i)})\\log (1-h(z(\\theta)^{(i)}))\\tag{5} $$\n",
        "* $m$ es la cantidad de ejemplos de entrenamiento\n",
        "* $y^{(i)}$ es la etiqueta real del i-√©simo dato de entrenamiento.\n",
        "* $h(z(\\theta)^{(i)})$ es la predicci√≥n del modelo para el i-√©simo ejemplo de entrenamiento.\n",
        "\n",
        "La funci√≥n de p√©rdida para un solo ejemplo de entrenamiento es\n",
        "$$ Loss = -1 \\times \\left( y^{(i)}\\log (h(z(\\theta)^{(i)})) + (1-y^{(i)})\\log (1-h(z(\\theta)^{(i)})) \\right)$$\n",
        "\n",
        "* Todos los valores de $ h $ est√°n entre 0 y 1, por lo que los registros ser√°n negativos. Esa es la raz√≥n del factor -1 aplicado a la suma de los dos t√©rminos de p√©rdida.\n",
        "* Tenga en cuenta que cuando el modelo predice 1 ($ h (z (\\theta)) = 1 $) y la etiqueta $ y $ tambi√©n es 1, la p√©rdida para ese ejemplo de entrenamiento es 0.\n",
        "* De manera similar, cuando el modelo predice 0 ($ h (z (\\theta)) = 0 $) y la etiqueta real tambi√©n es 0, la p√©rdida para ese ejemplo de entrenamiento es 0.\n",
        "* Sin embargo, cuando la predicci√≥n del modelo es cercana a 1 ($ h (z (\\theta)) = 0.9999 $) y la etiqueta es 0, el segundo t√©rmino de la p√©rdida logar√≠tmica se convierte en un gran n√∫mero negativo, que luego se multiplica por el factor general de -1 para convertirlo en un valor de p√©rdida positivo. $ -1 \\times (1 - 0) \\times log (1 - 0.9999) \\approx 9.2 $ Cuanto m√°s se acerque la predicci√≥n del modelo a 1, mayor ser√° la p√©rdida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTXYL2zY5ue6"
      },
      "source": [
        "* Del mismo modo, si el modelo predice cerca de 0 ($ h (z) = 0.0001 $) pero la etiqueta real es 1, el primer t√©rmino en la funci√≥n de p√©rdida se convierte en un n√∫mero grande: $ -1 \\times log (0.0001) \\approx 9.2 $. Cuanto m√°s cercana sea la predicci√≥n a cero, mayor ser√° la p√©rdida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "EJantc7j5ue6",
        "outputId": "85639db8-fc97-4c81-bb92-f194946276e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.210340371976182"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "#verificar que cuando el modelo predice cerca de 0 pero la etiqueta real es 1, la p√©rdida es un valor positivo grande\n",
        "-1 * np.log(0.0001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqOXSd3w5ue7"
      },
      "source": [
        "#### Actualizar los pesos\n",
        "\n",
        "Para actualizar su vector de peso $ \\theta $, aplicar√° el descenso de gradiente para mejorar iterativamente las predicciones de su modelo.\n",
        "El gradiente de la funci√≥n de costo $ J $ con respecto a uno de los pesos $ \\theta_j $ es:\n",
        "\n",
        "$$\\nabla_{\\theta_j}J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m(h^{(i)}-y^{(i)})x_j \\tag{5}$$\n",
        "* 'i' es el √≠ndice de todos los ejemplos de formaci√≥n \"m\".\n",
        "* 'j' es el √≠ndice del peso $ \\theta_j $, entonces $ x_j $ es la caracter√≠stica asociada con el peso $ \\theta_j $\n",
        "\n",
        "* Para actualizar el peso $ \\theta_j $, lo ajustamos restando una fracci√≥n del gradiente determinado por $ \\alpha $:\n",
        "$$ \\theta_j = \\theta_j - \\alpha \\times \\nabla_{\\theta_j} J (\\theta) $$\n",
        "* La tasa de aprendizaje $ \\alpha $ es un valor que elegimos para controlar qu√© tan grande ser√° una sola actualizaci√≥n.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSmgL_tL5ue7"
      },
      "source": [
        "## Implementaci√≥n de la funci√≥n Gradiente Descendente\n",
        "* El n√∫mero de iteraciones `num_iters` es el n√∫mero de veces que utilizar√° todo el conjunto de entrenamiento.\n",
        "* Para cada iteraci√≥n, calcular√° la funci√≥n de costo usando todos los ejemplos de entrenamiento (hay ejemplos de entrenamiento `m`), y para todas las funciones.\n",
        "* En lugar de actualizar un solo peso $ \\theta_i $ a la vez, podemos actualizar todos los pesos en el vector de columna:  \n",
        "$$\\mathbf{\\theta} = \\begin{pmatrix}\n",
        "\\theta_0\n",
        "\\\\\n",
        "\\theta_1\n",
        "\\\\\n",
        "\\theta_2\n",
        "\\\\\n",
        "\\vdots\n",
        "\\\\\n",
        "\\theta_n\n",
        "\\end{pmatrix}$$\n",
        "* $ \\mathbf {\\theta} $ tiene dimensiones (n + 1, 1), donde 'n' es el n√∫mero de caracter√≠sticas, y hay un elemento m√°s para el t√©rmino de sesgo $ \\theta_0 $ (tenga en cuenta que el valor de caracter√≠stica correspondiente $ \\mathbf {x_0} $ es 1).\n",
        "* Los 'logits', 'z', se calculan multiplicando la matriz de caracter√≠sticas 'x' con el vector de peso 'theta'.  $z = \\mathbf{x}\\mathbf{\\theta}$\n",
        "    * $\\mathbf{x}$ has dimensions (m, n+1)\n",
        "    * $\\mathbf{\\theta}$: has dimensions (n+1, 1)\n",
        "    * $\\mathbf{z}$: has dimensions (m, 1)\n",
        "* La predicci√≥n 'h' se calcula aplicando el sigmoide a cada elemento en 'z': $ h (z) = sigmoid (z) $, y tiene dimensiones (m, 1).\n",
        "* La funci√≥n de costo $ J $ se calcula tomando el producto escalar de los vectores 'y' y 'log (h)'. Dado que tanto 'y' como 'h' son vectores de columna (m, 1), transponga el vector a la izquierda, de modo que la multiplicaci√≥n de matrices de un vector de fila con un vector de columna realice el producto escalar.\n",
        "$$J = \\frac{-1}{m} \\times \\left(\\mathbf{y}^T \\cdot log(\\mathbf{h}) + \\mathbf{(1-y)}^T \\cdot log(\\mathbf{1-h}) \\right)$$\n",
        "* La actualizaci√≥n de theta tambi√©n est√° vectorizada. Debido a que las dimensiones de $ \\mathbf {x} $ son (m, n + 1), y tanto $ \\mathbf {h} $ como $ \\mathbf {y} $ son (m, 1), necesitamos transponer $ \\mathbf {x} $ y col√≥quelo a la izquierda para realizar la multiplicaci√≥n de matrices, que luego da la respuesta (n + 1, 1) que necesitamos:\n",
        "$$\\mathbf{\\theta} = \\mathbf{\\theta} - \\frac{\\alpha}{m} \\times \\left( \\mathbf{x}^T \\cdot \\left( \\mathbf{h-y} \\right) \\right)$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "Xh9MRYBM5ue7"
      },
      "outputs": [],
      "source": [
        "\n",
        "def gradientDescent(x, y, theta, alpha, num_iters):\n",
        "    m = x.shape[0]\n",
        "\n",
        "    for i in range(0, num_iters):\n",
        "      z = np.dot(x,theta)\n",
        "      h = sigmoid(z)\n",
        "\n",
        "      J = -1/m * (np.dot(y.transpose(), np.log(h)) + np.dot((1-y).transpose(), np.log(1-h)))\n",
        "\n",
        "      theta = theta - (alpha/m)*np.dot(x.transpose(), (h-y))\n",
        "\n",
        "      J = float(J)\n",
        "    return J, theta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQevcJBo5ue7"
      },
      "source": [
        "# Actividad 3: Modelo de Regresi√≥n Log√≠stica para An√°lisis de Sentimientos de tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coBT7VFB5ue7"
      },
      "source": [
        "### 1.- Entrenar el modelo\n",
        "\n",
        "**instrucciones: Para entrenar el modelo:**\n",
        "\n",
        "* Apile las caracter√≠sticas de todos los datos de entrenamiento en una matriz `X`.\n",
        "* Llame la funci√≥n `gradientDescent`, que se implement√≥ anteriormente.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "h1_zm4bj5ue7"
      },
      "outputs": [],
      "source": [
        "# recolectar todos los features apartir de la funci√≥n extract_features\n",
        "X = np.zeros((len(train_x),3))\n",
        "for i in range(len(train_x)):\n",
        "  X[i,:] = extract_features(train_x[i], freqs)\n",
        "\n",
        "# Obtener las etiquetas reales (el valor de y) train_y\n",
        "Y= train_y\n",
        "\n",
        "# Aplicar el gradiente descendente\n",
        "theta_0 = np.zeros((3,1)) # vector de 3x1 (inicializar aleatoriamente, o con zeros)\n",
        "J, theta = gradientDescent(X,Y,theta_0, 1e-9, 1500)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "theta"
      ],
      "metadata": {
        "id": "R2RFQgS0Nhyf",
        "outputId": "ab57f25e-7b28-471c-9f17-f5c0d0035fd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 7.25222017e-08],\n",
              "       [ 5.23753412e-04],\n",
              "       [-5.55251200e-04]])"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlVysRLb5ue8"
      },
      "source": [
        "### 2.- Probando la regresi√≥n log√≠stica\n",
        "\n",
        "**Instrucciones para Predecir si un tweet es positivo o negativo**\n",
        "\n",
        "* Dado un tweet, proc√©selo y luego extraiga las caracter√≠sticas.\n",
        "* Aplicar los pesos aprendidos del modelo para obtener los logits.\n",
        "* Aplicar la funci√≥n sigmoide a los logits para obtener la predicci√≥n (un valor entre 0 y 1).\n",
        "\n",
        "$$y_{pred} = sigmoid(\\mathbf{x} \\cdot \\theta)$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "98B0zMFU5ue8"
      },
      "outputs": [],
      "source": [
        "# UNQ_C4 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
        "def predict_tweet(tweet, freqs, theta):\n",
        "\n",
        "    #extraer los features con la funci√≥n extract featurs X\n",
        "    x = extract_features(tweet, freqs)\n",
        "\n",
        "    #predecir utilizando la ecuacion de arriba ypred = sigmoid(np.dot(x, theta))\n",
        "    y_pred = sigmoid(np.dot(x,theta))\n",
        "    if y_pred >0.5:\n",
        "      y_hat = 1\n",
        "    else:\n",
        "      y_hat = 0\n",
        "\n",
        "    return y_pred, y_hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "X9VcbIHO5ue8",
        "outputId": "2493cb85-4765-46f0-df51-d3c3d76f46cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am happy ---> (array([[0.51857391]]), 1)\n",
            "I am bad ---> (array([[0.49433751]]), 0)\n",
            "This movie is amazing ---> (array([[0.50356881]]), 1)\n",
            "great movie ---> (array([[0.5153249]]), 1)\n"
          ]
        }
      ],
      "source": [
        "tweets_test = ['I am happy', 'I am bad', 'This movie is amazing', 'great movie']\n",
        "for tw in tweets_test:\n",
        "  print(f'{tw} ---> {predict_tweet(tw, freqs,theta)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80BfnIgl5ue8"
      },
      "source": [
        "### 3.- Verificando el rendimiento del modelo\n",
        "\n",
        "Despu√©s de entrenar su modelo con el conjunto de entrenamiento anterior, verifique c√≥mo podr√≠a funcionar su modelo en datos reales no vistos prob√°ndolo con el conjunto de prueba.\n",
        "\n",
        "**Instrucciones: Implementar `test_logistic_regression`**\n",
        "\n",
        "* Dados los datos de prueba y los pesos de su modelo entrenado, calcule la precisi√≥n de su modelo de regresi√≥n log√≠stica.\n",
        "* Utilice su funci√≥n `predict_tweet ()` para hacer predicciones en cada tweet en el conjunto de prueba.\n",
        "* Si la predicci√≥n es> 0,5, establezca la clasificaci√≥n del modelo `y_hat` en 1; de lo contrario, establezca la clasificaci√≥n del modelo` y_hat` en 0.\n",
        "* Una predicci√≥n es precisa cuando `y_hat` es igual a` test_y`. Para calcular la precis√≥n sume todas las instancias en las que ($y_hat==test_y$) sean iguales y divida por `m`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byNb5piH5ue8"
      },
      "outputs": [],
      "source": [
        "# UNQ_C5 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)None\n",
        "def test_logistic_regression(test_x, test_y, freqs, theta):\n",
        "\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPiF3csd5ue8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgsnkbyG5ue8"
      },
      "source": [
        "### 4.- Predice tu propio tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HrMr7m15ue9"
      },
      "outputs": [],
      "source": [
        "# Feel free to change the tweet below\n",
        "my_tweet = 'This is a ridiculously bright movie. The plot was terrible and I was sad until the ending!'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_UABv9ymPopl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fpyOwrJCPpRj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "coursera": {
      "schema_names": [
        "NLPC1-1"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}